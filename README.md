# nlp-qlm-chatbot
A locally deployed 4-bit quantized Mistral-7B chatbot served via FastAPI and tunneled with ngrok, demonstrating efficient LLM inference on constrained GPU hardware.
